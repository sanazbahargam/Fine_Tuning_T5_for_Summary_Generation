{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Fine Tuning T5 for Summary Generation with PyTorch Lightning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "291595e38bf84090afe62de2d3bf27e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e974c99671e4aa9be6d19845ec3a683",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d51dadb8b9124a248476935f902d8892",
              "IPY_MODEL_34d7a4572c354534a29a0da83723d5cd"
            ]
          }
        },
        "5e974c99671e4aa9be6d19845ec3a683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "d51dadb8b9124a248476935f902d8892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc40651da43849b7b00b1f55cf22b526",
            "_dom_classes": [],
            "description": "Validation sanity check: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eba539275b7c4725ac88408c2fefeed4"
          }
        },
        "34d7a4572c354534a29a0da83723d5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_139c82a943014d37a6cfe4ee51f56a2e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226/? [00:36&lt;00:00,  7.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1258d77bef5f44dc8ce8c5d8bbb7660f"
          }
        },
        "cc40651da43849b7b00b1f55cf22b526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eba539275b7c4725ac88408c2fefeed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "139c82a943014d37a6cfe4ee51f56a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1258d77bef5f44dc8ce8c5d8bbb7660f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "422ce9c2cdca458bbc725c830f5d7e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f88f2136867492cb18854b44601e3c1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_596a88d9fae4465fb31e0d9405868917",
              "IPY_MODEL_0e53a627a75e4931b62a51996515bae9"
            ]
          }
        },
        "1f88f2136867492cb18854b44601e3c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "596a88d9fae4465fb31e0d9405868917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3417617909124dc29a0cd92e8463c84b",
            "_dom_classes": [],
            "description": "Epoch 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2032,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2032,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e42261b114e546efb80ce92a14a0a98c"
          }
        },
        "0e53a627a75e4931b62a51996515bae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_560e1f93f12b49c88d866e24a61171a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2032/2032 [31:51&lt;00:00,  1.06it/s, loss=2.055, v_num=al_0]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c1f1cc6e9ac457485fa3a8b99250380"
          }
        },
        "3417617909124dc29a0cd92e8463c84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e42261b114e546efb80ce92a14a0a98c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "560e1f93f12b49c88d866e24a61171a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c1f1cc6e9ac457485fa3a8b99250380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83262af6e506491f8a9f3e30c19a0d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e389616468b4d74a2a6202ca8fdc384",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0eb21047a4e1493abbe624742aebce2b",
              "IPY_MODEL_f669b69a532e498097f65b4221c6eb2c"
            ]
          }
        },
        "4e389616468b4d74a2a6202ca8fdc384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "0eb21047a4e1493abbe624742aebce2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_90a2686eb68347dd96339c4636209e23",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac9d456a19ca4154abc322dccca85794"
          }
        },
        "f669b69a532e498097f65b4221c6eb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c7784429cc748a1afc11739f4aaeea0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226/226 [01:37&lt;00:00,  6.93it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c8a04c50c98431ba28b422e4be97e29"
          }
        },
        "90a2686eb68347dd96339c4636209e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac9d456a19ca4154abc322dccca85794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c7784429cc748a1afc11739f4aaeea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c8a04c50c98431ba28b422e4be97e29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "981f337da1914d24b579823b4ccce282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e97de5f1d6f4c8baba9b40193703630",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f735b74a1fd4413b34001d9ad42d07c",
              "IPY_MODEL_cf5bf19c5ccc453b8ad2013e85548e93"
            ]
          }
        },
        "5e97de5f1d6f4c8baba9b40193703630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "8f735b74a1fd4413b34001d9ad42d07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_46aa809fcf084efe98c6e2fffed2fd4a",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c607caa573142bc9114e40aa2362c99"
          }
        },
        "cf5bf19c5ccc453b8ad2013e85548e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84976320f8934354aa29e98e0012d7aa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226/226 [01:38&lt;00:00,  6.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f09c26321b944148658fcefd322b678"
          }
        },
        "46aa809fcf084efe98c6e2fffed2fd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c607caa573142bc9114e40aa2362c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84976320f8934354aa29e98e0012d7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f09c26321b944148658fcefd322b678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d193a21f2d649b6a8b05f311672d0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_87a06401753f472c88dd303d87d4591e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9042d64054884f9aad49e46e77206a7a",
              "IPY_MODEL_f3ddfadf61db4d969ee944c875b24d48"
            ]
          }
        },
        "87a06401753f472c88dd303d87d4591e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "9042d64054884f9aad49e46e77206a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_684f4fd42d3740949a17c287afc8a1eb",
            "_dom_classes": [],
            "description": "Testing: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6079f4ec367f4f549021ff3464e7e406"
          }
        },
        "f3ddfadf61db4d969ee944c875b24d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_065e1605b74d46cbbd067d046c8b198d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226/226 [00:50&lt;00:00,  4.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85c4e833676c4e0aaa845e322652da7c"
          }
        },
        "684f4fd42d3740949a17c287afc8a1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6079f4ec367f4f549021ff3464e7e406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "065e1605b74d46cbbd067d046c8b198d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85c4e833676c4e0aaa845e322652da7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanazbahargam/Fine_Tuning_T5_for_Summary_Generation/blob/main/Fine_Tuning_T5_for_Summary_Generation_with_PyTorch_Lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdIeIP3UkR20"
      },
      "source": [
        "# Fine Tuning T5 for Summary Generation, with PyTorch Lightning\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U5-lpUtxwla"
      },
      "source": [
        "[My blog posts](https://sanazbahargam.github.io/year-archive/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V15VG18qYc2w"
      },
      "source": [
        "# Resources:\n",
        "*   Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, [paper](https://arxiv.org/abs/1910.10683) \n",
        "*   [T5 Implementation on PyTorch](https://github.com/huggingface/transformers/blob/455c6390938a5c737fa63e78396cedae41e4e87e/src/transformers/modeling_t5.py) by HuggingFace\n",
        "*  [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning)\n",
        "*  [Optuna](https://optuna.org/): An open source hyperparameter optimization framework to automate hyperparameter search\n",
        "* [ROUGE Score](https://pypi.org/project/rouge-score/)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JQkuINic0g_"
      },
      "source": [
        "# T5 Overview\n",
        "T5 was introduced in the paper [_Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer_](https://arxiv.org/abs/1910.10683). In that paper, authors provided a comprehensive picture of how we pre-trained a standard text-to-text Transformer model on a large text corpus, achieving state-of-the-art results on many NLP tasks after fine-tuning.\n",
        "\n",
        "They pre-trained T5 on a mixture of supervised and unsupervised tasks with the majoriy of data coming from an unlabeled dataset they developed called [C4](https://www.tensorflow.org/datasets/catalog/c4). C4 is based on a massive scrape of the web produced by [Common Crawl](https://commoncrawl.org). Loosely speaking, pre-training on C4 ideally gives T5 an understanding of natural language in addition to general world knowledge.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqmnRpXidJmL"
      },
      "source": [
        "##  A Shared Text-To-Text Framework\n",
        "\n",
        "With T5, authors propose reframing all NLP tasks into a unified text-to-text-format where the input and output are always text strings, in contrast to BERT-style models that can only output either a class label or a span of the input. This text-to-text framework allows us to use the same model, loss function, and hyperparameters on any NLP task, including machine translation, document summarization, question answering, and classification tasks (e.g., sentiment analysis). T5 can even be applied to regression tasks by training it to predict the string representation of a number instead of the number itself [source](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html).\n",
        "\n",
        "<img src=\"https://1.bp.blogspot.com/-o4oiOExxq1s/Xk26XPC3haI/AAAAAAAAFU8/NBlvOWB84L0PTYy9TzZBaLf6fwPGJTR0QCLcBGAsYHQ/s1600/image3.gif\" width=\"700\" height=\"300\" />\n",
        "\n",
        "<font color=\"grey\">Diagram of our text-to-text framework. Every task we consider uses text as input to the model, which is trained to generate some target text. This allows us to use the same model, loss function, and hyperparameters across our diverse set of tasks including translation (green), linguistic acceptability (red), sentence similarity (yellow), and **document summarization (blue)**. </font> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e77A4Gank3V"
      },
      "source": [
        "## Installation\n",
        "Installing the required packages, here's a breief decription of each package:\n",
        "*  Optuna: An open source hyperparameter optimization framework to automate hyperparameter search\n",
        "*  pytorch_lightning: An open-source Python library providing a lightweight PyTorch wrapper for high-performance AI research; to scale your models, not the boilerplate.\n",
        "*  Transformers: Provides thousands of pretrained models to perform tasks on various tasks.  Transformers is backed by the two most popular deep learning libraries, PyTorch and TensorFlow. \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD_vnyLXZQzD",
        "outputId": "84b54e03-7758-4a53-affb-1bf304142641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "!pip uninstall tensorflow-tensorboard -q\n",
        "!pip install --upgrade tensorflow -q\n",
        "!pip install optuna -q\n",
        "!pip install pytorch_lightning -q\n",
        "!pip install rouge-score -q\n",
        "!pip install transformers -q\n",
        "\n",
        "# Code for TPU packages install\n",
        "# !curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow-tensorboard as it is not installed.\u001b[0m\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320.4MB 48kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256kB 3.2MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 6.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 5.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 5.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 8.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 6.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143kB 7.8MB/s \n",
            "\u001b[?25h  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409kB 3.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.8MB 6.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 829kB 36.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 276kB 37.8MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.3.1 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 2.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 3.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 12.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 30.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 51.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKvPGLBQqzVM"
      },
      "source": [
        "Importing stock libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzM1_ykHaFur"
      },
      "source": [
        "import argparse\n",
        "from argparse import ArgumentParser\n",
        "from os.path import join, isfile\n",
        "from os import listdir\n",
        "import optuna\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from rouge_score import rouge_scorer\n",
        "import shutil\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import  DataLoader, RandomSampler, SequentialSampler #Dataset,\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poPNw7XwpeXv"
      },
      "source": [
        "Let's see the GPU we get from Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvPxXdKJguYB",
        "outputId": "ab64dd67-17d4-4b9c-9f34-bbb52a16a29c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Checking out the GPU we have access to. This is output is from the google colab version. \n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Oct  5 14:54:20 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     7W /  75W |     10MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQk_S7k5V5Cf"
      },
      "source": [
        "class MetricsCallback(pl.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.metrics = []\n",
        "\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        self.metrics.append(trainer.callback_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtI92WcVHrCb"
      },
      "source": [
        "class T5Finetuner(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, args, df):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.args = args\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(self.args.model)\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(self.args.model)\n",
        "        self.data = df\n",
        "        self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    def encode_text(self, context, text):\n",
        "      ctext = str(context)\n",
        "      ctext = ' '.join(ctext.split())\n",
        "      text = str(text) #summarized text\n",
        "      text = ' '.join(text.split())\n",
        "      source = self.tokenizer.batch_encode_plus([ctext], \n",
        "                                                max_length= self.args.source_len, \n",
        "                                                truncation=True,\n",
        "                                                #pad_to_max_length=True,\n",
        "                                                padding='max_length',\n",
        "                                                return_tensors='pt')\n",
        "      target = self.tokenizer.batch_encode_plus([text], \n",
        "                                                max_length= self.args.summ_len,\n",
        "                                                truncation=True,\n",
        "                                                #pad_to_max_length=True,\n",
        "                                                padding='max_length',\n",
        "                                                return_tensors='pt')\n",
        "      y = target['input_ids']\n",
        "      target_id = y[:, :-1].contiguous()\n",
        "      target_label = y[:, 1:].clone().detach()\n",
        "      target_label[y[:, 1:] == self.tokenizer.pad_token_id] = -100 #in case the labels are not provided, empty string\n",
        "      return source['input_ids'], source['attention_mask'], target_id, target_label\n",
        "    \n",
        "    def prepare_data(self):\n",
        "        source_ids, source_masks, target_ids, target_labels = [], [], [], [] \n",
        "        for _, row in self.data.iterrows():\n",
        "            source_id, source_mask, target_id, target_label = self.encode_text(row.ctext, row.text)\n",
        "            source_ids.append(source_id)\n",
        "            source_masks.append(source_mask)\n",
        "            target_ids.append(target_id)\n",
        "            target_labels.append(target_label)\n",
        "\n",
        "        # Convert the lists into tensors\n",
        "        source_ids = torch.cat(source_ids, dim=0)\n",
        "        source_masks = torch.cat(source_masks, dim=0)\n",
        "        target_ids = torch.cat(target_ids, dim=0)\n",
        "        target_labels = torch.cat(target_labels, dim=0)\n",
        "        # splitting the data to train, validation, and test\n",
        "        data = TensorDataset(source_ids, source_masks, target_ids, target_labels)\n",
        "        train_size, val_size = int(0.8 * len(data)), int(0.1 * len(data))\n",
        "        test_size = len(data) - (train_size + val_size)\n",
        "        self.train_dat, self.val_dat, self.test_dat = \\\n",
        "            random_split(data, [train_size, val_size, test_size])\n",
        "    \n",
        "    def forward(self, batch, batch_idx):\n",
        "        source_ids, source_mask, target_ids, target_labels = batch[:4]\n",
        "        return self.model(input_ids = source_ids, attention_mask = source_mask, \n",
        "                          decoder_input_ids=target_ids, labels=target_labels)\n",
        "        \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self(batch, batch_idx)[0]\n",
        "        return {'loss': loss, 'log': {'train_loss': loss}}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self(batch, batch_idx)[0]\n",
        "        return {'loss': loss}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        loss = sum([o['loss'] for o in outputs]) / len(outputs)\n",
        "        out = {'val_loss': loss}\n",
        "        return {**out, 'log': out}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss = self(batch, batch_idx)[0]\n",
        "        return {'loss': loss}\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        loss = sum([o['loss'] for o in outputs]) / len(outputs)\n",
        "        out = {'test_loss': loss}\n",
        "        return {**out, 'log': out}\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dat, batch_size=self.args.bs,\n",
        "                          num_workers=4, sampler=RandomSampler(self.train_dat))\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dat, batch_size=self.args.bs, num_workers=4,\n",
        "                          sampler=SequentialSampler(self.val_dat))\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dat, batch_size=self.args.bs, num_workers=4,\n",
        "                          sampler=SequentialSampler(self.test_dat))    \n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.model.parameters(), lr=self.args.lr, eps=1e-4)\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps=0,\n",
        "            num_training_steps=self.args.max_epochs * len(self.train_dat))\n",
        "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
        "    \n",
        "    def generate_summary(self, ctext, summ_len=150, text='', beam_search=2, repetition_penalty=2.5):\n",
        "        source_id, source_mask, target_id, target_label = self.encode_text(ctext, text)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            generated_ids = self.model.generate(\n",
        "                input_ids = source_id,\n",
        "                attention_mask = source_mask, \n",
        "                max_length=summ_len, \n",
        "                truncation=True,\n",
        "                num_beams=beam_search,\n",
        "                repetition_penalty=repetition_penalty, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            prediction = [self.tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "        if len(text) > 0:\n",
        "            target = [self.tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in target_id]\n",
        "            scores = self.scorer.score(target[0], prediction[0])\n",
        "            return prediction, scores\n",
        "        else:\n",
        "            return prediction\n",
        "        \n",
        "\n",
        "    def save_core_model(self):\n",
        "        store_path = join(self.args.output, self.args.name, 'core')\n",
        "        self.model.save_pretrained(store_path)\n",
        "        self.tokenizer.save_pretrained(store_path)\n",
        "        \n",
        "    @staticmethod\n",
        "    def add_model_specific_args(parent_parser):\n",
        "        p = ArgumentParser(parents=[parent_parser], add_help=False)\n",
        "        p.add_argument('-m', '--model', type=str, default='t5-base',\n",
        "                       help='name of the model or the path pointing to it')\n",
        "        p.add_argument('--bs', '--batch_size', type=int, default=2)\n",
        "        p.add_argument('--source_len', type=int, default=512)\n",
        "        p.add_argument('--summ_len', type=int, default=150)\n",
        "        return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAlC7iXriFy3"
      },
      "source": [
        "def parse_arguments():\n",
        "    p = ArgumentParser()\n",
        "    p.add_argument('-p', '--path', type=str,  \n",
        "                   default='/content/gdrive/My Drive/Colab Notebooks/data/text_summarization_t5/news_summary.csv',\n",
        "                  help='path to the data file')\n",
        "    p.add_argument('-o', '--output', type=str, default='/tmp/tpu-template',\n",
        "                  help='path to the output directory for storing the model')\n",
        "    p.add_argument('-n', '--name', type=str, default='t5-base',\n",
        "                  help='this name will be used on tensorboard for the model')\n",
        "    p.add_argument('-t', '--trials', type=int, default=1,\n",
        "                  help='number of trials for hyperparameter search')\n",
        "    p.add_argument('--seed', type=int, default=0, help='randomization seed')\n",
        "    p = T5Finetuner.add_model_specific_args(p)\n",
        "    p = pl.Trainer.add_argparse_args(p)\n",
        "    args,_ = p.parse_known_args()\n",
        "    args.max_epochs = 2\n",
        "    return args\n",
        "\n",
        "def optuna_objective(trial, args):\n",
        "    # sampling the hyperparameters\n",
        "    args.lr = trial.suggest_categorical(\"lr\", [1e-6, 5e-6, 1e-5, 5e-5, 1e-4])\n",
        "    # setting up the right callbacks\n",
        "    cp_callback = pl.callbacks.ModelCheckpoint(\n",
        "        join(args.output, args.name, f\"trial_{trial.number}\", \"{epoch}\"),\n",
        "        monitor=\"val_loss\", mode=\"min\")\n",
        "    pr_callback = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
        "    metrics_callback = MetricsCallback()\n",
        "    df = pd.read_csv(args.path, engine='python')\n",
        "    summarizer = T5Finetuner(args, df)         # loading the model\n",
        "    trainer = pl.Trainer.from_argparse_args(      # loading the trainer\n",
        "        args, gpus=(1 if torch.cuda.is_available() else 0),\n",
        "        default_root_dir=args.output, gradient_clip_val=1.0,\n",
        "        checkpoint_callback=cp_callback, callbacks=[metrics_callback],\n",
        "        early_stop_callback=pr_callback, num_sanity_val_steps=-1,\n",
        "        # select TensorBoad or Wandb logger\n",
        "        logger=TensorBoardLogger(join(args.output, 'logs'), name=args.name, version=f'trial_{trial.number}')\n",
        "        )\n",
        "  \n",
        "    trainer.fit(summarizer)                       # fitting the model\n",
        "    trainer.test(summarizer)                      # testing the model\n",
        "    return min([x['val_loss'].item() for x in metrics_callback.metrics])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9SWwdl9mmYB"
      },
      "source": [
        "def main():\n",
        "    import glob\n",
        "    import os\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/gdrive')\n",
        "    # Setting up the device for GPU usage\n",
        "    from torch import cuda\n",
        "    device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Preparing for TPU usage, if you don't have access ot TPU, remove these comments\n",
        "    # import torch_xla\n",
        "    # import torch_xla.core.xla_model as xm\n",
        "    # device = xm.xla_device() \n",
        "\n",
        "    args = parse_arguments()      \n",
        "    # parsing the input arguments\n",
        "    shutil.rmtree(join(args.output, args.name), ignore_errors=True)\n",
        "    shutil.rmtree(join(args.output, 'logs', args.name), ignore_errors=True)\n",
        "    pl.seed_everything(args.seed)             # making it reproducible\n",
        "\n",
        "    # creating a study for hyperparameter search\n",
        "    pruner = optuna.pruners.MedianPruner()\n",
        "    study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
        "    study.optimize(lambda x: optuna_objective(x, args), n_trials=args.trials)\n",
        "    # Loading the best model and saving the core bert model inside it\n",
        "    best_trial_number = study.best_trial.number\n",
        "    path = join(args.output, args.name, f\"trial_{best_trial_number}\")\n",
        "    model_file = [f for f in listdir(path) if isfile(join(path, f))][0]\n",
        "    t5model = T5Finetuner.load_from_checkpoint(join(path, model_file))\n",
        "    t5model.save_core_model()\n",
        "\n",
        "    print(\"\\n Let's test the model on a wikipedia page:\")\n",
        "    prediction, scores = t5model.generate_summary('''Avram Noam Chomsky (born December 7, 1928) is an American linguist, philosopher, cognitive scientist, historian, social critic, and political activist. Sometimes called \"the father of modern linguistics\", Chomsky is also a major figure in analytic philosophy, and is one of the founders of the field of cognitive science. He is Laureate Professor of Linguistics at the University of Arizona and Institute Professor Emeritus at the Massachusetts Institute of Technology (MIT), and is the author of more than 100 books on topics such as linguistics, war, politics, and mass media. Ideologically, he aligns with anarcho-syndicalism and libertarian socialism. Born to Ashkenazi Jewish immigrants in Philadelphia, Chomsky developed an early interest in anarchism from alternative bookstores in New York City. He studied at the University of Pennsylvania. During his postgraduate work in the Harvard Society of Fellows, Chomsky developed the theory of transformational grammar for which he earned his doctorate in 1955. That year he began teaching at MIT, and in 1957 emerged as a significant figure in linguistics with his landmark work Syntactic Structures, which played a major role in remodeling the study of language. From 1958 to 1959 Chomsky was a National Science Foundation fellow at the Institute for Advanced Study. He created or co-created the universal grammar theory, the generative grammar theory, the Chomsky hierarchy, and the minimalist program. Chomsky also played a pivotal role in the decline of linguistic behaviorism, and was particularly critical of the work of B. F. Skinner. An outspoken opponent of U.S. involvement in the Vietnam War, which he saw as an act of American imperialism, in 1967 Chomsky rose to national attention for his anti-war essay \"The Responsibility of Intellectuals\". Associated with the New Left, he was arrested multiple times for his activism and placed on President Richard Nixon's Enemies List. While expanding his work in linguistics over subsequent decades, he also became involved in the linguistics wars. In collaboration with Edward S. Herman, Chomsky later articulated the propaganda model of media criticism in Manufacturing Consent and worked to expose the Indonesian occupation of East Timor. His defense of freedom of speech, including Holocaust denial, generated significant controversy in the Faurisson affair of the 1980s. Since retiring from MIT, he has continued his vocal political activism, including opposing the 2003 invasion of Iraq and supporting the Occupy movement. Chomsky began teaching at the University of Arizona in 2017.''',\n",
        "                            summ_len=90,\n",
        "                            text= '''Avram Noam Chomsky was born on December 7, 1928, in the East Oak Lane neighborhood of Philadelphia, Pennsylvania. His parents, Ze'ev \"William\" Chomsky and Elsie Simonofsky, were Jewish immigrants. William had fled the Russian Empire in 1913 to escape conscription and worked in Baltimore sweatshops and Hebrew elementary schools before attending university''',\n",
        "    )\n",
        "    print('Generated summary:\\n', prediction, '\\nROUGE score:\\n', scores)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtNs9ytpCow2",
        "outputId": "75d9ea20-e034-4301-8464-2cf9630f2875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696,
          "referenced_widgets": [
            "291595e38bf84090afe62de2d3bf27e5",
            "5e974c99671e4aa9be6d19845ec3a683",
            "d51dadb8b9124a248476935f902d8892",
            "34d7a4572c354534a29a0da83723d5cd",
            "cc40651da43849b7b00b1f55cf22b526",
            "eba539275b7c4725ac88408c2fefeed4",
            "139c82a943014d37a6cfe4ee51f56a2e",
            "1258d77bef5f44dc8ce8c5d8bbb7660f",
            "422ce9c2cdca458bbc725c830f5d7e81",
            "1f88f2136867492cb18854b44601e3c1",
            "596a88d9fae4465fb31e0d9405868917",
            "0e53a627a75e4931b62a51996515bae9",
            "3417617909124dc29a0cd92e8463c84b",
            "e42261b114e546efb80ce92a14a0a98c",
            "560e1f93f12b49c88d866e24a61171a6",
            "5c1f1cc6e9ac457485fa3a8b99250380",
            "83262af6e506491f8a9f3e30c19a0d63",
            "4e389616468b4d74a2a6202ca8fdc384",
            "0eb21047a4e1493abbe624742aebce2b",
            "f669b69a532e498097f65b4221c6eb2c",
            "90a2686eb68347dd96339c4636209e23",
            "ac9d456a19ca4154abc322dccca85794",
            "1c7784429cc748a1afc11739f4aaeea0",
            "4c8a04c50c98431ba28b422e4be97e29",
            "981f337da1914d24b579823b4ccce282",
            "5e97de5f1d6f4c8baba9b40193703630",
            "8f735b74a1fd4413b34001d9ad42d07c",
            "cf5bf19c5ccc453b8ad2013e85548e93",
            "46aa809fcf084efe98c6e2fffed2fd4a",
            "5c607caa573142bc9114e40aa2362c99",
            "84976320f8934354aa29e98e0012d7aa",
            "1f09c26321b944148658fcefd322b678",
            "0d193a21f2d649b6a8b05f311672d0a0",
            "87a06401753f472c88dd303d87d4591e",
            "9042d64054884f9aad49e46e77206a7a",
            "f3ddfadf61db4d969ee944c875b24d48",
            "684f4fd42d3740949a17c287afc8a1eb",
            "6079f4ec367f4f549021ff3464e7e406",
            "065e1605b74d46cbbd067d046c8b198d",
            "85c4e833676c4e0aaa845e322652da7c"
          ]
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-10-05 16:25:08,783] A new study created in memory with name: no-name-86cbc9cb-c6a4-461b-8cbc-c9f1282ada57\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning:\n",
            "\n",
            "Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "\n",
            "\n",
            "  | Name  | Type                       | Params\n",
            "-----------------------------------------------------\n",
            "0 | model | T5ForConditionalGeneration | 222 M \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "291595e38bf84090afe62de2d3bf27e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layoutâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "422ce9c2cdca458bbc725c830f5d7e81",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83262af6e506491f8a9f3e30c19a0d63",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning:\n",
            "\n",
            "Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "981f337da1914d24b579823b4ccce282",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving latest checkpoint..\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning:\n",
            "\n",
            "Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d193a21f2d649b6a8b05f311672d0a0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_loss': tensor(1.8394, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-10-05 17:31:10,780] Trial 0 finished with value: 1.8311350345611572 and parameters: {'lr': 5e-06}. Best is trial 0 with value: 1.8311350345611572.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Let's test the model on a wikipedia page:\n",
            "Generated summary:\n",
            " ['Avram Noam Chomsky (born December 7, 1928) is an American linguist, philosopher, cognitive scientist, historian, social critic, and political activist. Born to Ashkenazi Jewish immigrants in Philadelphia, Chomsky developed an early interest in anarchism from alternative bookstores in New York City. He is the author of more than 100 books on topics such as linguistics, war, politics'] \n",
            "ROUGE score:\n",
            " {'rouge1': Score(precision=0.3333333333333333, recall=0.3584905660377358, fmeasure=0.34545454545454546), 'rouge2': Score(precision=0.08928571428571429, recall=0.09615384615384616, fmeasure=0.0925925925925926), 'rougeL': Score(precision=0.21052631578947367, recall=0.22641509433962265, fmeasure=0.21818181818181817)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjXuiMMlWMy7"
      },
      "source": [
        "If you are running this code on Google Colab, depending on your input size and batch size, you may get \n",
        "\n",
        "<font color=\"red\">RuntimeError: cuda runtime error : out of memory.</font> \n",
        "\n",
        "In that case you can free the CUDA memory and reduce the batch size and run the code again. In order to free CUDA memory, you can use the following code to see the used/avialable memery, free the CUDA memroy and see the used/avaliable memory again.\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc-690VwqBwh",
        "outputId": "0bf2ed12-2dd5-4b40-8659-7c75076939f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install py3nvml -q \n",
        "from py3nvml.py3nvml import * \n",
        "import gc\n",
        "def get_cuda_memory_info():\n",
        "  t = torch.cuda.get_device_properties(0).total_memory\n",
        "  c = torch.cuda.memory_cached(0)\n",
        "  a = torch.cuda.memory_allocated(0)\n",
        "  f = c-a  # free inside cache\n",
        "  nvmlInit()\n",
        "  h = nvmlDeviceGetHandleByIndex(0)\n",
        "  info = nvmlDeviceGetMemoryInfo(h)\n",
        "  print(f'\\ntotal    : {info.total/1000000} * 10^6')\n",
        "  print(f'free     : {info.free/1000000} * 10^6')\n",
        "  print(f'used     : {info.used/1000000} * 10^6')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 2.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_NnutzkqGBR",
        "outputId": "170cca4f-ce76-40f0-f451-9684de0a325e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "get_cuda_memory_info()\n",
        "gc.collect() \n",
        "torch.cuda.empty_cache()\n",
        "get_cuda_memory_info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning:\n",
            "\n",
            "torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "total    : 7981.694976 * 10^6\n",
            "free     : 4925.095936 * 10^6\n",
            "used     : 3056.59904 * 10^6\n",
            "\n",
            "total    : 7981.694976 * 10^6\n",
            "free     : 7223.574528 * 10^6\n",
            "used     : 758.120448 * 10^6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}